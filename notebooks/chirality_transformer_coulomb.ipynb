{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2928583-5503-49f3-90c4-1d86bbb32309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 12:51:51.868665: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 12:51:55.772875: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-30 12:52:02.638654: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.20.0 . Executing eagerly? True\n",
      "Number of GPUs:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1764525125.381816 1605803 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# standard python\n",
    "import numpy as np\n",
    "import scipy\n",
    "#import pathlib\n",
    "\n",
    "import os\n",
    "# plotting, especially for jupyter notebooks\n",
    "import matplotlib\n",
    "#matplotlib.rcParams['text.usetex'] = True # breaks for some endpoint labels\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution() # needed for tf version 1 or it stages operations but does not do them\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "# local routines\n",
    "#from chemdataprep import load_PDBs,load_countsfromPDB,load_diametersfromPDB,find_chemnames\n",
    "#from toxmathandler import load_tscores\n",
    "\n",
    "#checkpoint_path = \"/home2/ajgreen4/Read-Across_w_GAN/Models/cp.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "print(\"tensorflow version\",tf.__version__,\". Executing eagerly?\",tf.executing_eagerly())\n",
    "print(\"Number of GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964acb3-d6e8-462c-a11d-88300b4f25fb",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52e408f-3a74-4d33-a2fd-eb7e000e7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data, val and test data\n",
    "file_path = 'train.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    train_df = pickle.load(file)\n",
    "#print(train_df)\n",
    "# good fit = lower negative number\n",
    "# more negative docking score = better fit \n",
    "\n",
    "\n",
    "# Load validation data\n",
    "file_path = 'validation_small_enantiomers_stable_full_screen_docking_MOL_margin3_49878_10368_5184.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    val_df = pickle.load(file)\n",
    "#print(val_df)\n",
    "\n",
    "\n",
    "# Load test data\n",
    "file_path = 'test_small_enantiomers_stable_full_screen_docking_MOL_margin3_50571_10368_5184.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    test_df = pickle.load(file)\n",
    "#print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0296a-4393-4560-af1e-9aa499cef9a1",
   "metadata": {},
   "source": [
    "# Get atoms in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5017bb-0e5e-4273-a2de-8017a60304c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86459db-cd7a-4246-81e4-8aadaffd2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sample (first molecule):\n",
      "[('Br', array([-2.04649997, -1.8743    ,  0.33809999])), ('C', array([1.38030005, 0.0871    , 0.14910001])), ('C', array([ 0.0986    , -0.0115    ,  0.83929998])), ('C', array([0.90759999, 1.29069996, 0.8251    ])), ('C', array([ 2.61890006, -0.6832    ,  0.1062    ])), ('C', array([ 1.89660001, -0.2475    , -1.17390001])), ('C', array([-1.22039998, -0.1279    ,  0.1161    ])), ('C', array([-1.46070004,  0.5363    , -1.21200001])), ('C', array([-2.17440009,  1.03050005,  0.012     ]))]\n",
      "Val Sample (first molecule):\n",
      "[('Br', array([-3.21449995, -0.0071    , -0.52410001])), ('N', array([0.5399    , 1.46490002, 0.80440003])), ('C', array([ 0.59130001, -1.55040002,  0.7726    ])), ('C', array([-0.83429998, -1.36479998,  0.2483    ])), ('C', array([ 1.75919998, -1.22930002, -0.1627    ])), ('C', array([-1.23389995, -0.0048    , -0.33129999])), ('C', array([ 1.72179997,  0.0517    , -0.99519998])), ('C', array([-0.85650003,  1.25820005,  0.44670001])), ('C', array([ 1.52699995,  1.38160002, -0.25870001]))]\n",
      "Test Sample (first molecule):\n",
      "[('O', array([ 1.37290001, -1.18830001, -1.25969994])), ('N', array([-0.0825    ,  0.31889999, -0.26429999])), ('N', array([-0.52770001, -2.40199995,  0.7816    ])), ('C', array([-1.33589995, -0.42030001, -0.42340001])), ('C', array([-2.3994    ,  0.67919999, -0.4826    ])), ('C', array([-1.81560004,  1.78400004,  0.39129999])), ('C', array([-0.3281    ,  1.71669996,  0.081     ])), ('C', array([-1.56659997, -1.38460004,  0.73799998])), ('C', array([ 1.15970004, -0.2446    , -0.50590003])), ('C', array([2.29180002, 0.33129999, 0.18529999])), ('C', array([3.23140001, 0.8096    , 0.75870001]))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def atomic_number_to_symbol(atomic_number):\n",
    "    periodic_table = {\n",
    "        1: 'H', 6: 'C', 7: 'N', 8: 'O', 9: 'F',\n",
    "        15: 'P', 16: 'S', 17: 'Cl', 35: 'Br', 53: 'I'\n",
    "    }\n",
    "    return periodic_table.get(atomic_number, 'Unknown')\n",
    "\n",
    "# Define dataset paths\n",
    "datasets = {\n",
    "    'train': 'train.pkl',\n",
    "    'val': 'validation_small_enantiomers_stable_full_screen_docking_MOL_margin3_49878_10368_5184.pkl',\n",
    "    'test': 'test_small_enantiomers_stable_full_screen_docking_MOL_margin3_50571_10368_5184.pkl'\n",
    "}\n",
    "\n",
    "mollists = {}\n",
    "\n",
    "for dataset_name, file_path in datasets.items():\n",
    "    with open(file_path, 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "    \n",
    "    mollist = []\n",
    "    for mol in df['rdkit_mol_cistrans_stereo']:\n",
    "        molecule = []\n",
    "        if mol is not None and isinstance(mol, Chem.Mol):\n",
    "            if mol.GetNumConformers() > 0:\n",
    "                conf = mol.GetConformer(0)\n",
    "                for atom in mol.GetAtoms():\n",
    "                    atomic_number = atom.GetAtomicNum()\n",
    "                    atom_type = atomic_number_to_symbol(atomic_number)\n",
    "                    pos = conf.GetAtomPosition(atom.GetIdx())\n",
    "                    coordinates = np.array([pos.x, pos.y, pos.z])\n",
    "                    molecule.append((atom_type, coordinates))\n",
    "        mollist.append(molecule)\n",
    "    \n",
    "    mollists[dataset_name] = mollist\n",
    "    print(f\"{dataset_name.capitalize()} Sample (first molecule):\")\n",
    "    print(mollist[0] if mollist else \"No valid molecules found.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d9ae50-94db-4151-893a-8d6ff9d8d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, val, split to get views\n",
    "train_mollist = mollists['train']\n",
    "val_mollist = mollists['val']\n",
    "test_mollist = mollists['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2653344-bc7d-4941-a624-52e6169a2f17",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aec1a24-2176-4694-acbe-96f24ff7dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 267 μs, sys: 27 μs, total: 294 μs\n",
      "Wall time: 301 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = train_mollist    \n",
    "y_train = train_df['top_score']\n",
    "\n",
    "X_val = val_mollist             \n",
    "y_val = val_df['top_score']    \n",
    "\n",
    "X_test = test_mollist          \n",
    "y_test = test_df['top_score']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3179fd-f45d-4d7e-a615-8b7b0fc9325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def speciesmap(atom_type):\n",
    "    atom_to_number = {\n",
    "        'H': 1,   # Hydrogen\n",
    "        'C': 6,   # Carbon\n",
    "        'N': 7,   # Nitrogen\n",
    "        'O': 8,   # Oxygen\n",
    "        'F': 9,   # Fluorine\n",
    "        'P': 15,  # Phosphorus\n",
    "        'S': 16,  # Sulfur\n",
    "        'Cl': 17, # Chlorine\n",
    "        'Br': 35, # Bromine\n",
    "        'I': 53   # Iodine\n",
    "    }\n",
    "    return np.array([atom_to_number.get(atom_type, 0)])  # Returns 0 if atom type is not recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598b332f-c4af-473a-a991-8cbf6ba5d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights and views\n",
    "ws_train = np.load('ws_train.npy')\n",
    "vs_train = np.load('vs_train.npy')\n",
    "ws_val = np.load('ws_val.npy')\n",
    "vs_val = np.load('vs_val.npy')\n",
    "ws_test = np.load('ws_test.npy')\n",
    "vs_test = np.load('vs_test.npy')\n",
    "\n",
    "# Load dimensions\n",
    "Natoms_train = np.load('Natoms_train.npy')\n",
    "Nviews_train = np.load('Nviews_train.npy')\n",
    "Natoms_val = np.load('Natoms_val.npy')\n",
    "Nviews_val = np.load('Nviews_val.npy')\n",
    "Natoms_test = np.load('Natoms_test.npy')\n",
    "Nviews_test = np.load('Nviews_test.npy')\n",
    "\n",
    "chiral_train = [ws_train, vs_train]\n",
    "chiral_val = [ws_val, vs_val]\n",
    "chiral_test = [ws_test, vs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfd9831-526b-43d2-a714-3925c669b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234622, 29)\n",
      "(234622, 29, 116)\n",
      "(49878, 29)\n",
      "(49878, 29, 116)\n",
      "(50571, 29)\n",
      "(50571, 29, 116)\n"
     ]
    }
   ],
   "source": [
    "print(ws_train.shape)\n",
    "print(vs_train.shape)\n",
    "print(ws_val.shape)\n",
    "print(vs_val.shape)\n",
    "print(ws_test.shape)\n",
    "print(vs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54347749-6407-4939-a9a7-afec4c784437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234622, 29, 29, 4)\n",
      "(49878, 29, 29, 4)\n",
      "(50571, 29, 29, 4)\n"
     ]
    }
   ],
   "source": [
    "from qm7_transformercode import small_views\n",
    "single_atom_train = small_views(vs_train)\n",
    "single_atom_val = small_views(vs_val)\n",
    "single_atom_test = small_views(vs_test)\n",
    "print(single_atom_train.shape)\n",
    "print(single_atom_val.shape)\n",
    "print(single_atom_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921f73aa-d20b-4049-9599-2070883f73dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded atom embeddings!\n"
     ]
    }
   ],
   "source": [
    "atom_embeddings_train = np.load(\"atom_embeddings_train.npy\", mmap_mode='r')\n",
    "atom_embeddings_val   = np.load(\"atom_embeddings_val.npy\",   mmap_mode='r')\n",
    "atom_embeddings_test  = np.load(\"atom_embeddings_test.npy\",  mmap_mode='r')\n",
    "\n",
    "print(\"Loaded atom embeddings!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc70b422-ae32-45c1-aba8-59f1f83973ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234622, 29, 29, 20)\n",
      "(49878, 29, 29, 20)\n",
      "(50571, 29, 29, 20)\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(atom_embeddings_train.shape) # atomic number (1), 3d coordinates (3), single atom properties (8), padded zero (4)\n",
    "print(atom_embeddings_val.shape)\n",
    "print(atom_embeddings_test.shape)\n",
    "print(atom_embeddings_train.dtype)\n",
    "print(atom_embeddings_val.dtype)\n",
    "print(atom_embeddings_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cafe436-491a-448a-af98-62cb463593c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([  35.   ,    0.   ,    0.   ,    0.   ,    2.96 ,   79.904,\n",
       "           7.   ,   17.   ,  120.   , 1139.9  ,  324.6  ,   23.5  ,\n",
       "           0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,\n",
       "           0.   ,    0.   ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_embeddings_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e57880bd-1c7f-4fab-b55c-04d07f53be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234622, 29, 29, 20)\n",
      "(49878, 29, 29, 20)\n",
      "(50571, 29, 29, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Copy data\n",
    "Xtr = atom_embeddings_train.copy()\n",
    "Xval = atom_embeddings_val.copy()\n",
    "Xte = atom_embeddings_test.copy()\n",
    "\n",
    "# Create masks (nonzero atoms)\n",
    "mask_tr = (Xtr[..., 0] != 0)\n",
    "mask_val = (Xval[..., 0] != 0)\n",
    "mask_te = (Xte[..., 0] != 0)\n",
    "\n",
    "# Fit scaler ONLY on training atom properties\n",
    "props_tr = Xtr[..., 4:12][mask_tr]   # assuming properties are columns 4–11 (8 features)\n",
    "prop_scaler = StandardScaler().fit(props_tr)\n",
    "\n",
    "# Apply transform to all three sets\n",
    "Xtr[..., 4:12][mask_tr]  = prop_scaler.transform(Xtr[..., 4:12][mask_tr])\n",
    "Xval[..., 4:12][mask_val] = prop_scaler.transform(Xval[..., 4:12][mask_val])\n",
    "Xte[..., 4:12][mask_te]  = prop_scaler.transform(Xte[..., 4:12][mask_te])\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xval.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b910be-9b41-4b79-8b4c-f4e2957e194e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.        ,  0.        ,  0.        ,  0.        ,  0.72364863,\n",
       "       21.91144044,  3.98654186,  2.5486692 ,  7.97021195, -0.13421879,\n",
       "        3.37350309,  3.12961286,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9238e5e-e4a2-493a-8228-ad5c0643d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelsG_train = y_train \n",
    "labelsG_val = y_val     \n",
    "labelsG_test = y_test   \n",
    "Ntoxicity = 3  \n",
    "\n",
    "ws_train, vs_train = ws_train, Xtr \n",
    "ws_val, vs_val = ws_val, Xval   \n",
    "ws_test, vs_test = ws_test, Xte  \n",
    "\n",
    "\n",
    "dataG_train = [ws_train, vs_train]\n",
    "dataG_val = [ws_val, vs_val]              \n",
    "dataG_test = [ws_test, vs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "846ca148-f123-4876-99e9-7cb68d93c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "(234622,)\n",
      "(49878,)\n",
      "(50571,)\n"
     ]
    }
   ],
   "source": [
    "print(type(labelsG_train))\n",
    "print(type(labelsG_test))\n",
    "print(type(dataG_train))\n",
    "print(type(dataG_val))\n",
    "print(type(dataG_test))\n",
    "\n",
    "\n",
    "print(labelsG_train.shape)\n",
    "print(labelsG_val.shape)\n",
    "print(labelsG_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e848cf-5cda-45a2-95fb-e7a61b1fb612",
   "metadata": {},
   "source": [
    "# Compute Coulomb matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acaac2a5-83fa-4f49-b3b9-f04956eccbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coulomb_matrix_for_view(view):\n",
    "    \"\"\"\n",
    "    Compute Coulomb matrix for a single view.\n",
    "    \n",
    "    Parameters:\n",
    "    - view: numpy array of shape (29, 4) where each row is [atomic_number, x, y, z]\n",
    "    \n",
    "    Returns:\n",
    "    - coulomb_matrix: numpy array of shape (29, 29)\n",
    "    \"\"\"\n",
    "    n_atoms = view.shape[0]\n",
    "    coulomb_matrix = np.zeros((n_atoms, n_atoms))\n",
    "    \n",
    "    for i in range(n_atoms):\n",
    "        atomic_num_i = view[i, 0]\n",
    "        if atomic_num_i == 0:\n",
    "            continue\n",
    "            \n",
    "        coords_i = view[i, 1:4]\n",
    "        \n",
    "        for j in range(n_atoms):\n",
    "            atomic_num_j = view[j, 0]\n",
    "            if atomic_num_j == 0:  # Skip padding atoms\n",
    "                continue\n",
    "                \n",
    "            coords_j = view[j, 1:4]\n",
    "            \n",
    "            if i == j:\n",
    "                # Diagonal element: self-interaction\n",
    "                coulomb_matrix[i, j] = 0.5 * atomic_num_i ** 2.4\n",
    "            else:\n",
    "                # Off-diagonal element: interaction between atoms i and j\n",
    "                dist = np.linalg.norm(coords_i - coords_j)\n",
    "                coulomb_matrix[i, j] = atomic_num_i * atomic_num_j / dist\n",
    "                \n",
    "    return coulomb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a20d0415-2111-41d9-ae36-6349bc60e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_coulomb_matrices_for_views(views_data):\n",
    "    \"\"\"\n",
    "    Precompute Coulomb matrices for all views in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - views_data: numpy array of shape (batch_size, num_views, num_atoms, 4)\n",
    "    \n",
    "    Returns:\n",
    "    - coulomb_matrices: numpy array of shape (batch_size, num_views, num_atoms, num_atoms)\n",
    "    \"\"\"\n",
    "    batch_size, num_views, num_atoms, _ = views_data.shape\n",
    "    coulomb_matrices = np.zeros((batch_size, num_views, num_atoms, num_atoms))\n",
    "    \n",
    "    for batch_idx in range(batch_size):\n",
    "        for view_idx in range(num_views):\n",
    "            view = views_data[batch_idx, view_idx]\n",
    "            coulomb_matrices[batch_idx, view_idx] = compute_coulomb_matrix_for_view(view)\n",
    "                \n",
    "    return coulomb_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8475ee2-0212-43b4-ab3e-0f085d1648c3",
   "metadata": {},
   "source": [
    "# Load Coulomb matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0d4f3cb-237a-49be-a839-33a594dc3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "coulomb_train = np.load(\"coulomb_train.npy\", mmap_mode='r')\n",
    "coulomb_val   = np.load(\"coulomb_val.npy\",   mmap_mode='r')\n",
    "coulomb_test  = np.load(\"coulomb_test.npy\",  mmap_mode='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1083aa70-445e-4cf7-8a4a-d6a8774a7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234622, 29, 29, 29)\n",
      "(49878, 29, 29, 29)\n",
      "(50571, 29, 29, 29)\n"
     ]
    }
   ],
   "source": [
    "print(coulomb_train.shape)\n",
    "print(coulomb_val.shape)\n",
    "print(coulomb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c97dd874-dc27-4814-a02b-d6f66660c063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([2539.41283766,  107.98894501,   72.79267883,   71.78925323,\n",
       "          71.77416992,   53.12495804,   48.20129013,   46.40313339,\n",
       "          43.5627861 ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coulomb_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "507f4568-c34d-4575-8a33-f24b44dba993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow as tf\n",
    "from rdkit import Chem\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932d2a8-3968-4237-902d-80c7df58418a",
   "metadata": {},
   "source": [
    "# Transformer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65ee40-4f6b-49e2-9c88-83408d2c12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, LayerNormalization, Dense\n",
    "\n",
    "class AtomAttention(Layer):\n",
    "    \n",
    "    def __init__(self, d_k=32, d_v=16, **kwargs):\n",
    "        \"\"\"\n",
    "        Single-head atom-atom self-attention with optional Coulomb bias.\n",
    "        d_k = dimension of query/key\n",
    "        d_v = dimension of value\n",
    "        \"\"\"\n",
    "        super(AtomAttention, self).__init__(**kwargs)\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.norm = LayerNormalization(axis=-1, epsilon=1e-6)\n",
    "        self.alpha = None  # scaling for Coulomb\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # input_shape: (batch, views, atoms, features)\n",
    "        self.batch_size  = input_shape[0]\n",
    "        self.num_views   = input_shape[1]\n",
    "        self.num_atoms   = input_shape[2]\n",
    "        self.feature_dim = input_shape[3]\n",
    "        \n",
    "        self.W_q = self.add_weight(\n",
    "            name='W_q',\n",
    "            shape=(self.feature_dim, self.d_k),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.W_k = self.add_weight(\n",
    "            name='W_k',\n",
    "            shape=(self.feature_dim, self.d_k),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.W_v = self.add_weight(\n",
    "            name='W_v',\n",
    "            shape=(self.feature_dim, self.d_v),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.W_o = self.add_weight(\n",
    "            name='W_o',\n",
    "            shape=(self.d_v, self.feature_dim),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha',\n",
    "            shape=(),\n",
    "            initializer=tf.keras.initializers.Constant(0.1),\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs, coulomb_matrix=None):\n",
    "        \"\"\"\n",
    "        inputs:  (batch, views, atoms, features)\n",
    "        coulomb_matrix: (batch, views, atoms, atoms) or None\n",
    "        output:  (batch, views, atoms, features)\n",
    "        \"\"\"\n",
    "        \n",
    "        reshaped_input = tf.reshape(inputs, [-1, self.num_atoms, self.feature_dim])\n",
    "        \n",
    "        # Q, K, V\n",
    "        Q = tf.matmul(reshaped_input, self.W_q)  # (batch*views, atoms, d_k)\n",
    "        K = tf.matmul(reshaped_input, self.W_k)  # (batch*views, atoms, d_k)\n",
    "        V = tf.matmul(reshaped_input, self.W_v)  # (batch*views, atoms, d_v)\n",
    "        \n",
    "        # Raw attention scores\n",
    "        scores = tf.matmul(Q, K, transpose_b=True)  # (batch*views, atoms, atoms)\n",
    "        scaled_scores = scores / tf.math.sqrt(tf.cast(self.d_k, tf.float32))\n",
    "        \n",
    "        #\n",
    "        if coulomb_matrix is not None:\n",
    "            # coulomb_matrix: (batch, views, atoms, atoms) -> (batch*views, atoms, atoms)\n",
    "            coulomb_reshaped = tf.reshape(\n",
    "                coulomb_matrix,\n",
    "                [-1, self.num_atoms, self.num_atoms]\n",
    "            )\n",
    "            # make sure types match\n",
    "            coulomb_reshaped = tf.cast(coulomb_reshaped, scaled_scores.dtype)\n",
    "            scaled_scores = scaled_scores + self.alpha * coulomb_reshaped\n",
    "        \n",
    "        # Mask zero-padded atoms (as in your original code)\n",
    "        input_sums = tf.reduce_sum(tf.abs(inputs), axis=[0, 1, 3])  # (atoms,)\n",
    "        mask_atoms = tf.equal(input_sums, 0.0)  # True for padded atoms\n",
    "        \n",
    "        mask_rows = tf.expand_dims(mask_atoms, 1)  # (atoms, 1)\n",
    "        mask_cols = tf.expand_dims(mask_atoms, 0)  # (1, atoms)\n",
    "        mask = tf.logical_or(mask_rows, mask_cols)  # (atoms, atoms)\n",
    "        \n",
    "        batch_views = tf.shape(scaled_scores)[0]\n",
    "        mask = tf.tile(tf.expand_dims(mask, 0), [batch_views, 1, 1])  # (batch*views, atoms, atoms)\n",
    "        \n",
    "        # Softmax\n",
    "        attn_weight = tf.nn.softmax(scaled_scores, axis=-1)\n",
    "        \n",
    "        # Apply mask AFTER softmax: zero out masked positions\n",
    "        attn_weight = tf.where(mask, 0.0, attn_weight)\n",
    "        \n",
    "        # Weighted sum of values\n",
    "        attn_output = tf.matmul(attn_weight, V)  # (batch*views, atoms, d_v)\n",
    "        \n",
    "        # Project back to feature space\n",
    "        project_output = tf.matmul(attn_output, self.W_o)  # (batch*views, atoms, features)\n",
    "        \n",
    "        # Residual + LayerNorm\n",
    "        skip_output = project_output + reshaped_input\n",
    "        normed = self.norm(skip_output)\n",
    "        \n",
    "        # Reshape back to (batch, views, atoms, features)\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        final_output = tf.reshape(\n",
    "            normed,\n",
    "            [batch_size, self.num_views, self.num_atoms, self.feature_dim]\n",
    "        )\n",
    "        return final_output\n",
    "\n",
    "\n",
    "class FeedForward(Layer):\n",
    "    \"\"\"Position-wise feed-forward net with residual + LayerNorm.\"\"\"\n",
    "    def __init__(self, d_model=20, d_ff=64, **kwargs):\n",
    "        super(FeedForward, self).__init__(**kwargs)\n",
    "        self.fc1 = Dense(d_ff, activation='relu', name='ffn_fc1')\n",
    "        self.fc2 = Dense(d_model, name='ffn_fc2')\n",
    "        self.norm = LayerNormalization(axis=-1, epsilon=1e-6, name='ffn_norm')\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self.fc1(x)\n",
    "        y = self.fc2(y)\n",
    "        return self.norm(x + y)\n",
    "\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    \"\"\"\n",
    "    Single Transformer encoder block: AtomAttention (+Coulomb) + FeedForward.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=20, d_k=32, d_v=16, d_ff=64, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.attn = AtomAttention(d_k=d_k, d_v=d_v, name='atom_attention')\n",
    "        self.ffn = FeedForward(d_model=d_model, d_ff=d_ff, name='ffn')\n",
    "\n",
    "    def call(self, x, coulomb_matrix=None):\n",
    "        x = self.attn(x, coulomb_matrix=coulomb_matrix)\n",
    "        x = self.ffn(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c94e66e-2553-473a-a5b9-6ed86e799683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ multiDense_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">338,723</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">583</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">340,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ multiDense_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,752</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ multiDense_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense0 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m338,723\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense3 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense4 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense5 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense6 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense7 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense8 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense9 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m583\u001b[0m)            │       \u001b[38;5;34m340,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ multiDense_output (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m1,752\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,723</span> (12.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,404,723\u001b[0m (12.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,723</span> (12.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,404,723\u001b[0m (12.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"parallelwrapper\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"parallelwrapper\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ parallelwrapper_in… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ unstack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Unstack</span>)   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ parallelwrapper_… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,723</span> │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>],    │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>],   │\n",
       "│                     │                   │            │ unstack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>]… │\n",
       "│                     │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ parallelScalars     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ parallelScalars[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ parallelwrapper_in… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m580\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ unstack (\u001b[38;5;33mUnstack\u001b[0m)   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),     │          \u001b[38;5;34m0\u001b[0m │ parallelwrapper_… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m580\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │  \u001b[38;5;34m3,404,723\u001b[0m │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m5\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m6\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m7\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m8\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m9\u001b[0m],    │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m10\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m11\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m12\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m13\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m14\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m15\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m16\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m17\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m18\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m19\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m20\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m21\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m22\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m23\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m24\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m25\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m26\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m27\u001b[0m],   │\n",
       "│                     │                   │            │ unstack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m28\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stack (\u001b[38;5;33mStack\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m4\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m5\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m6\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m7\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m8\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m9\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m10\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m11\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m12\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m13\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m14\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m15\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m16\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m17\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m18\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m19\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m20\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m21\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m22\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m23\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m24\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m25\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m26\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m27\u001b[0m]… │\n",
       "│                     │                   │            │ functional_1[\u001b[38;5;34m28\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ parallelScalars     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ stack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ parallelScalars[\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,723</span> (12.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,404,723\u001b[0m (12.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,723</span> (12.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,404,723\u001b[0m (12.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generic dense NN\n",
    "def multiDense(Nin,Nout,Nhidden,widthhidden=None,kernel_regularizer=None):\n",
    "    \"\"\"Construct a basic NN with some dense layers.\n",
    "    \n",
    "    :parameter Nin: The number of inputs\n",
    "    :type Nin: int\n",
    "    :parameter Nout: The number of outputs\n",
    "    :type Nout: int\n",
    "    :parameter Nhidden: The number of hidden layers.\n",
    "    :type Nhidden: int\n",
    "    :parameter widthhidden: The width of each hidden layer.\n",
    "        If left at None, Nin + Nout will be used.\n",
    "    :parameter kernel_regularizer: the regularizer to use, such as regularizers.l2(0.001)\n",
    "    :type kernel_regularizer: tensorflow.keras.regularizers.xxx\n",
    "    :returns: The NN model\n",
    "    :rtype: keras.Model\n",
    "    \n",
    "    \"\"\"\n",
    "    if widthhidden is None:\n",
    "        widthhidden = Nin + Nout\n",
    "    x = inputs = keras.Input(shape=(Nin,), name='multiDense_input')\n",
    "    if kernel_regularizer is not None:\n",
    "        print(\"Using regularization\")\n",
    "    for i in range(Nhidden):\n",
    "        x = layers.Dense(widthhidden, activation='relu', kernel_regularizer=kernel_regularizer,name='dense'+str(i))(x)\n",
    "#        x = layers.Dense(widthhidden, name='dense'+str(i))(x)\n",
    "#        x = tf.nn.leaky_relu(x, alpha=0.05)\n",
    "#    outputs = layers.Dense(Nout, activation='linear',name='multiDense_output')(x)\n",
    "    outputs = layers.Dense(Nout,name='multiDense_output')(x)\n",
    "    #outputs = tf.nn.leaky_relu(outputs, alpha=0.05)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)#, name='multiDense')\n",
    "if 1:\n",
    "    # manual check of multiDense\n",
    "    mmd = multiDense(580,3,10,583)\n",
    "    mmd.summary()\n",
    "    # used to do the weighted sum over views\n",
    "\n",
    "def parallelwrapper(Nparallel,basemodel,insteadmax=False):\n",
    "    \"\"\"Construct a model that applies a basemodel multiple times and take a weighted sum (or max) of the result.\n",
    "    \n",
    "    :parameter Nparallel: The number of times to apply in parallel\n",
    "    :type Nparallel: int\n",
    "    :parameter basemodel: a keras.Model inferred to have Nin inputs and Nout outputs.\n",
    "    :type basemodel: a keras.Model\n",
    "    :parameter insteadmax: If True, take the max of the results of the basemodel instead of the weighted sum.\n",
    "        For compatibility, the model is still constructed with weights as inputs, but it ignores them.\n",
    "    :type insteadmax: Boolean\n",
    "    :returns: model with inputs shape [(?,Nparallel),(?,Nin,Nparallel)] and outputs shape (?,Nout).\n",
    "        The first input is the scalar weights in the sum.\n",
    "    :rtype: keras.Model\n",
    "    \n",
    "    Note: We could do a max over the parallel applications instead of or in addition to the weighted sum.\n",
    "    \n",
    "    \"\"\"\n",
    "    # infer shape of basemodel inputs and outputs\n",
    "    Nin =  basemodel.inputs[0].shape[1]\n",
    "    Nout =  basemodel.outputs[0].shape[1]\n",
    "    \n",
    "    # Apply basemodel Nparallel times in parallel\n",
    "    # create main input (?,Nparallel,Nin) \n",
    "    parallel_inputs = keras.Input(shape=(Nparallel,Nin), name='parallelwrapper_input0')\n",
    "    # apply base NN to each parallel slice; outputs (?,Nparallel,Nout)\n",
    "    if False:\n",
    "        # original version, stopped working at some tensorflow update\n",
    "        xb = basemodel(parallel_inputs) # worked in earlier tensorflow\n",
    "        #xb = tf.map_fn(basemodel,parallel_inputs) # another version that fails\n",
    "    else:\n",
    "        # newer version, works but makes summary and graphing cumbersome\n",
    "        # unstack in the Nparallel directio\n",
    "        parallel_inputsunstacked = tf.keras.ops.unstack(parallel_inputs, Nparallel, 1)\n",
    "        # apply base NN to each \n",
    "        xbunstacked = [basemodel(x) for x in parallel_inputsunstacked]\n",
    "        # re-stack\n",
    "        xb = tf.keras.ops.stack(xbunstacked,axis=1)\n",
    "    \n",
    "    # create input scalars for weighted sun (?,Nparallel)\n",
    "    weight_inputs = keras.Input(shape=(Nparallel,), name='parallelScalars')\n",
    "    if insteadmax:\n",
    "        # take max over the Nparallel direction to get (?,1,Nout)\n",
    "        out = layers.MaxPool1D(pool_size=Nparallel)(xb)\n",
    "        # reshape to (?,Nout)\n",
    "        out = layers.Reshape((Nout,))(out)\n",
    "    else:\n",
    "        # do a weighted sum over the Nparallel direction to get (?,Nout)\n",
    "        out = layers.Dot((-2,-1))([xb,weight_inputs])\n",
    "    \n",
    "    return keras.Model(inputs=[weight_inputs,parallel_inputs], outputs=out, name='parallelwrapper')\n",
    "if 1:\n",
    "    # manual check\n",
    "    mmd = multiDense(580,3,10,583)\n",
    "    mpw = parallelwrapper(29,mmd,insteadmax=0)\n",
    "    mpw.summary()\n",
    "    # make models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44428c38-2c4a-400c-b1e0-c9b105d4ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_generator_with_transformer(\n",
    "    data, labels, baselayers, Nfeatures, endlayers, Nviews,\n",
    "    num_blocks=4, d_k=32, d_v=16, d_ff=64,\n",
    "    base_regularizer=None, end_regularizer=None\n",
    "):\n",
    "    \"\"\"\n",
    "    data: [ws, vs, coulomb] for the *whole dataset* (used to infer shapes)\n",
    "    \"\"\"\n",
    "    # data[1] is vs: (Nmol, Nviews, Natoms, d_model)\n",
    "    Natoms  = data[1].shape[2]\n",
    "    d_model = data[1].shape[3]\n",
    "    flattened_dim = Natoms * d_model\n",
    "    \n",
    "    # Inputs\n",
    "    weight_input = keras.Input(shape=(Nviews,), name='weight_input')              # (batch, Nviews)\n",
    "    atom_input   = keras.Input(shape=(Nviews, Natoms, d_model), name='atom_input')# (batch, Nviews, Natoms, d_model)\n",
    "    coulomb_input = keras.Input(\n",
    "        shape=(Nviews, Natoms, Natoms),\n",
    "        name='coulomb_input'\n",
    "    )  # (batch, Nviews, Natoms, Natoms)\n",
    "    \n",
    "    # Transformer blocks with Coulomb\n",
    "    x = atom_input\n",
    "    for i in range(num_blocks):\n",
    "        x = TransformerBlock(\n",
    "            d_model=d_model,\n",
    "            d_k=d_k,\n",
    "            d_v=d_v,\n",
    "            d_ff=d_ff,\n",
    "            name=f'transformer_block_{i}'\n",
    "        )(x, coulomb_matrix=coulomb_input)\n",
    "    \n",
    "    # Flatten per view\n",
    "    x = layers.Reshape((Nviews, flattened_dim), name='flatten_views')(x)\n",
    "    \n",
    "    # View-wise NN + weighted sum over views\n",
    "    Gbase = multiDense(flattened_dim, Nfeatures, baselayers, kernel_regularizer=base_regularizer)\n",
    "    Gpw   = parallelwrapper(Nviews, Gbase, insteadmax=False)\n",
    "    x = Gpw([weight_input, x])  # (batch, Nfeatures)\n",
    "    \n",
    "    # Final regressor\n",
    "    Gft = multiDense(Nfeatures, 1, endlayers, kernel_regularizer=end_regularizer)\n",
    "    output = Gft(x)  # (batch, 1)\n",
    "    \n",
    "    generator = keras.Model(\n",
    "        inputs=[weight_input, atom_input, coulomb_input],\n",
    "        outputs=output,\n",
    "        name='generator_with_transformer_coulomb'\n",
    "    )\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "025ad191-ec8e-4aaa-887e-c8c9e18b340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enantiomer_pairs(df):\n",
    "    \"\"\"\n",
    "    Extract enantiomer pairs from dataframe based on SMILES_nostereo.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    pairs = []\n",
    "    smiles_groups = df.groupby('SMILES_nostereo')\n",
    "    \n",
    "    for smiles, group in smiles_groups:\n",
    "        if len(group) >= 2:\n",
    "            score_groups = group.groupby('top_score')\n",
    "            enantiomer_data = []\n",
    "            for score, score_group in score_groups:\n",
    "                enantiomer_data.append({\n",
    "                    'conformers': score_group.index.tolist(),\n",
    "                    'top_score': score,\n",
    "                    'size': len(score_group)\n",
    "                })\n",
    "            if len(enantiomer_data) == 2:\n",
    "                if np.random.random() > 0.5:\n",
    "                    pairs.append({\n",
    "                        'enantiomer1_conformers': enantiomer_data[0]['conformers'],\n",
    "                        'enantiomer2_conformers': enantiomer_data[1]['conformers'],\n",
    "                        'enantiomer1_score': enantiomer_data[0]['top_score'],\n",
    "                        'enantiomer2_score': enantiomer_data[1]['top_score'],\n",
    "                        'smiles_nostereo': smiles\n",
    "                    })\n",
    "                else:\n",
    "                    pairs.append({\n",
    "                        'enantiomer1_conformers': enantiomer_data[1]['conformers'],\n",
    "                        'enantiomer2_conformers': enantiomer_data[0]['conformers'],\n",
    "                        'enantiomer1_score': enantiomer_data[1]['top_score'],\n",
    "                        'enantiomer2_score': enantiomer_data[0]['top_score'],\n",
    "                        'smiles_nostereo': smiles\n",
    "                    })\n",
    "    print(f\"Found {len(pairs)} enantiomer pairs\")\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def create_enantiomer_batch(pairs, data, labels, batch_size=32):\n",
    "    \"\"\"\n",
    "    data: [ws, vs, coulomb]\n",
    "    \"\"\"\n",
    "    batch_ws    = []\n",
    "    batch_vs    = []\n",
    "    batch_coul  = []\n",
    "    batch_scores = []\n",
    "    \n",
    "    ws, vs, coulomb = data\n",
    "    n_pairs = len(pairs)\n",
    "    \n",
    "    if n_pairs < batch_size // 2:\n",
    "        selected_pairs = np.random.choice(pairs, size=batch_size//2, replace=True)\n",
    "    else:\n",
    "        selected_pairs = np.random.choice(pairs, size=batch_size//2, replace=False)\n",
    "    \n",
    "    for pair in selected_pairs:\n",
    "        conf1_idx = np.random.choice(pair['enantiomer1_conformers'])\n",
    "        conf2_idx = np.random.choice(pair['enantiomer2_conformers'])\n",
    "        \n",
    "        batch_ws.extend([ws[conf1_idx], ws[conf2_idx]])\n",
    "        batch_vs.extend([vs[conf1_idx], vs[conf2_idx]])\n",
    "        batch_coul.extend([coulomb[conf1_idx], coulomb[conf2_idx]])\n",
    "        batch_scores.extend([labels[conf1_idx], labels[conf2_idx]])\n",
    "    \n",
    "    return (\n",
    "        np.array(batch_ws),\n",
    "        np.array(batch_vs),\n",
    "        np.array(batch_coul),\n",
    "        np.array(batch_scores).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "def train_with_enantiomer_sampling(\n",
    "    generator,\n",
    "    dataG_train, labelsG_train, train_df,\n",
    "    dataG_val,   labelsG_val,   val_df,\n",
    "    epochs=10, batch_size=32\n",
    "):\n",
    "    \"\"\"\n",
    "    dataG_*: [ws, vs, coulomb]\n",
    "    \"\"\"\n",
    "    enantiomer_pairs_train = get_enantiomer_pairs(train_df)\n",
    "    if not enantiomer_pairs_train:\n",
    "        raise ValueError(\"No enantiomer pairs found in training data!\")\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    best_weights = None\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    \n",
    "    num_batches_per_epoch = max(1, len(enantiomer_pairs_train) // (batch_size // 2))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\", end=' - ')\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_idx in range(num_batches_per_epoch):\n",
    "            batch_ws, batch_vs, batch_coul, batch_scores = create_enantiomer_batch(\n",
    "                enantiomer_pairs_train, dataG_train, labelsG_train, batch_size\n",
    "            )\n",
    "            loss = generator.train_on_batch(\n",
    "                [batch_ws, batch_vs, batch_coul],\n",
    "                batch_scores\n",
    "            )\n",
    "            loss = float(loss[0] if isinstance(loss, (list, tuple)) else loss)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches_per_epoch\n",
    "        print(f\"Loss: {avg_loss:.4f}\", end=' - ')\n",
    "        \n",
    "        val_accuracy = evaluate_ranking_accuracy(generator, dataG_val, labelsG_val, val_df)\n",
    "        print(f\"Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_weights = generator.get_weights()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    if best_weights is not None:\n",
    "        generator.set_weights(best_weights)\n",
    "    return generator, best_val_accuracy\n",
    "\n",
    "\n",
    "def evaluate_ranking_accuracy(model, data, labels, df, batch_size=32):\n",
    "    \"\"\"\n",
    "    data: [ws, vs, coulomb]\n",
    "    \"\"\"\n",
    "    ws, vs, coulomb = data\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(0, len(ws), batch_size):\n",
    "        batch_ws   = ws[i:i+batch_size]\n",
    "        batch_vs   = vs[i:i+batch_size]\n",
    "        batch_coul = coulomb[i:i+batch_size]\n",
    "        batch_preds = model.predict(\n",
    "            [batch_ws, batch_vs, batch_coul],\n",
    "            verbose=0\n",
    "        )\n",
    "        all_predictions.extend(batch_preds.flatten())\n",
    "    \n",
    "    all_predictions = np.array(all_predictions)\n",
    "    \n",
    "    pairs = get_enantiomer_pairs(df)\n",
    "    correct_rankings = 0\n",
    "    total_pairs = len(pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        preds1 = [all_predictions[idx] for idx in pair['enantiomer1_conformers']]\n",
    "        preds2 = [all_predictions[idx] for idx in pair['enantiomer2_conformers']]\n",
    "        avg_pred1 = np.mean(preds1)\n",
    "        avg_pred2 = np.mean(preds2)\n",
    "        true_score1 = pair['enantiomer1_score']\n",
    "        true_score2 = pair['enantiomer2_score']\n",
    "        pred_ranking = avg_pred1 < avg_pred2\n",
    "        true_ranking = true_score1 < true_score2\n",
    "        if pred_ranking == true_ranking:\n",
    "            correct_rankings += 1\n",
    "    \n",
    "    accuracy = correct_rankings / total_pairs if total_pairs > 0 else 0.0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d52c5c-411e-4394-90b9-635d94e20347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Hyperparameters ================\n",
      "Base layers:        4\n",
      "Base regularizer:   0\n",
      "Nfeatures:          3\n",
      "End layers:         2\n",
      "End regularizer:    0\n",
      "Nviews:             29\n",
      "Transformer params:\n",
      "  num_blocks:       4\n",
      "  d_k:              32\n",
      "  d_v:              20\n",
      "  d_ff:             64\n",
      "=================================================\n",
      "\n",
      "Starting training with enantiomer pair sampling...\n",
      "Training data:   234622 conformers\n",
      "Validation data: 49878 conformers\n",
      "Test data:       50571 conformers\n",
      "Found 24192 enantiomer pairs\n",
      "Epoch 1/50 - Loss: 2.4909 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.4973\n",
      "Epoch 2/50 - Loss: 1.1345 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.4996\n",
      "Epoch 3/50 - Loss: 1.0469 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.4983\n",
      "Epoch 4/50 - Loss: 1.0116 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.4878\n",
      "Epoch 5/50 - Loss: 0.9903 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.5015\n",
      "Epoch 6/50 - Loss: 0.9759 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.5002\n",
      "Epoch 7/50 - Loss: 0.9673 - Found 5184 enantiomer pairs\n",
      "Val Acc: 0.4967\n",
      "Epoch 8/50 - Loss: 0.9605 - "
     ]
    }
   ],
   "source": [
    "\n",
    "dataG_train = [\n",
    "    ws_train.astype('float32'),\n",
    "    Xtr.astype('float32'),\n",
    "    coulomb_train.astype('float32')\n",
    "]\n",
    "\n",
    "dataG_val = [\n",
    "    ws_val.astype('float32'),\n",
    "    Xval.astype('float32'),\n",
    "    coulomb_val.astype('float32')\n",
    "]\n",
    "\n",
    "dataG_test = [\n",
    "    ws_test.astype('float32'),\n",
    "    Xte.astype('float32'),\n",
    "    coulomb_test.astype('float32')\n",
    "]\n",
    "# Build model\n",
    "baselayers = 4\n",
    "base_reg   = 0\n",
    "Nfeatures  = 3\n",
    "endlayers  = 2\n",
    "end_reg    = 0\n",
    "Nviews     = 29\n",
    "# Print hyperparameters used\n",
    "print(\"\\n================ Hyperparameters ================\")\n",
    "print(f\"Base layers:        {baselayers}\")\n",
    "print(f\"Base regularizer:   {base_reg}\")\n",
    "print(f\"Nfeatures:          {Nfeatures}\")\n",
    "print(f\"End layers:         {endlayers}\")\n",
    "print(f\"End regularizer:    {end_reg}\")\n",
    "print(f\"Nviews:             {Nviews}\")\n",
    "print(\"Transformer params:\")\n",
    "print(f\"  num_blocks:       4\")\n",
    "print(f\"  d_k:              32\")\n",
    "print(f\"  d_v:              20\")\n",
    "print(f\"  d_ff:             64\")\n",
    "print(\"=================================================\\n\")\n",
    "\n",
    "\n",
    "base_regularizer = regularizers.l2(base_reg) if base_reg else None\n",
    "end_regularizer  = regularizers.l2(end_reg)  if end_reg  else None\n",
    "\n",
    "generator = init_generator_with_transformer(\n",
    "    dataG_train, labelsG_train,\n",
    "    baselayers, Nfeatures, endlayers, Nviews,\n",
    "    num_blocks=4, d_k=32, d_v=20, d_ff=64,\n",
    "    base_regularizer=base_regularizer,\n",
    "    end_regularizer=end_regularizer\n",
    ")\n",
    "generator.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "print(\"Starting training with enantiomer pair sampling...\")\n",
    "print(f\"Training data:   {len(train_df)} conformers\")\n",
    "print(f\"Validation data: {len(val_df)} conformers\")\n",
    "print(f\"Test data:       {len(test_df)} conformers\")\n",
    "\n",
    "trained_generator, best_val_accuracy = train_with_enantiomer_sampling(\n",
    "    generator, dataG_train, labelsG_train, train_df,\n",
    "    dataG_val,   labelsG_val,   val_df,\n",
    "    epochs=50, batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_accuracy = evaluate_ranking_accuracy(trained_generator, dataG_test, labelsG_test, test_df)\n",
    "print(f\"Final test ranking accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
